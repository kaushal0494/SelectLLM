{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f15cd1c2-d81c-49df-97fd-6b78dc0ecab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b107ff64-c912-41de-8eae-fc70599d25a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8792, 37) gsm8k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>split</th>\n",
       "      <th>subject_x</th>\n",
       "      <th>sr_gemma-7b-it_CHAT</th>\n",
       "      <th>sr_llama2-13b-chat_CHAT</th>\n",
       "      <th>sr_mistral-7b-inst_CHAT</th>\n",
       "      <th>maj_gemma-7b-it_CHAT</th>\n",
       "      <th>maj_llama2-13b-chat_CHAT</th>\n",
       "      <th>maj_mistral-7b-inst_CHAT</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_answers_gemma-7b</th>\n",
       "      <th>auto_answers_llama2-7b-lm</th>\n",
       "      <th>auto_answers_metamath-7b</th>\n",
       "      <th>auto_answers_mistral-7b-lm</th>\n",
       "      <th>auto_answers_olmo-7b</th>\n",
       "      <th>auto_answers_opt-6.7b</th>\n",
       "      <th>rl_gemma-7b</th>\n",
       "      <th>rl_mistral-7b-lm</th>\n",
       "      <th>rl_llama2-13b-chat</th>\n",
       "      <th>rl_gemma-7b-it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>D</td>\n",
       "      <td>train</td>\n",
       "      <td>moral_scenarios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['B', 'D', 'D', 'C', 'C', 'D', 'D', 'C', 'D', ...</td>\n",
       "      <td>['A', 'B', 'B', 'D', 'D', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>['D', 'D', 'D', 'D', 'D', 'D', 'D', 'B', 'D', ...</td>\n",
       "      <td>['C', 'C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>['C', 'C', 'D', 'C', 'B', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>A</td>\n",
       "      <td>train</td>\n",
       "      <td>moral_scenarios</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['B', 'A', 'B', 'B', 'B', 'A', 'B', 'A', 'B', ...</td>\n",
       "      <td>['B', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', ...</td>\n",
       "      <td>['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>['A', 'A', 'A', 'B', 'A', 'A', 'B', 'B', 'A', ...</td>\n",
       "      <td>['D', 'C', 'B', 'B', 'B', 'A', 'D', 'D', 'B', ...</td>\n",
       "      <td>['B', 'A', 'C', 'B', 'B', 'C', 'C', 'D', 'B', ...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>D</td>\n",
       "      <td>train</td>\n",
       "      <td>moral_scenarios</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['B', 'C', 'D', 'D', 'D', 'B', 'D', 'B', 'A', ...</td>\n",
       "      <td>['D', 'D', 'D', 'INVALID', 'A', 'D', 'C', 'D',...</td>\n",
       "      <td>['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>['B', 'D', 'D', 'D', 'A', 'B', 'C', 'INVALID',...</td>\n",
       "      <td>['C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'B', ...</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>B</td>\n",
       "      <td>train</td>\n",
       "      <td>moral_scenarios</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['A', 'B', 'B', 'A', 'B', 'A', 'A', 'B', 'B', ...</td>\n",
       "      <td>['A', 'A', 'D', 'B', 'B', 'D', 'A', 'A', 'A', ...</td>\n",
       "      <td>['D', 'D', 'D', 'D', 'D', 'D', 'D', 'B', 'D', ...</td>\n",
       "      <td>['A', 'B', 'A', 'D', 'A', 'A', 'A', 'A', 'B', ...</td>\n",
       "      <td>['D', 'A', 'C', 'D', 'C', 'D', 'A', 'C', 'D', ...</td>\n",
       "      <td>['B', 'INVALID', 'A', 'D', 'D', 'D', 'B', 'D',...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For which of these two scenarios does the main...</td>\n",
       "      <td>D</td>\n",
       "      <td>train</td>\n",
       "      <td>moral_scenarios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['D', 'C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>['D', 'D', 'D', 'INVALID', 'D', 'D', 'D', 'D',...</td>\n",
       "      <td>['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...</td>\n",
       "      <td>['D', 'D', 'D', 'A', 'D', 'B', 'C', 'D', 'B', ...</td>\n",
       "      <td>['D', 'D', 'C', 'D', 'C', 'D', 'D', 'B', 'D', ...</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question gold_answer  split  \\\n",
       "0  For which of these two scenarios does the main...           D  train   \n",
       "1  For which of these two scenarios does the main...           A  train   \n",
       "2  For which of these two scenarios does the main...           D  train   \n",
       "3  For which of these two scenarios does the main...           B  train   \n",
       "4  For which of these two scenarios does the main...           D  train   \n",
       "\n",
       "         subject_x  sr_gemma-7b-it_CHAT  sr_llama2-13b-chat_CHAT  \\\n",
       "0  moral_scenarios                  0.0                      0.8   \n",
       "1  moral_scenarios                  0.1                      0.0   \n",
       "2  moral_scenarios                  0.1                      0.9   \n",
       "3  moral_scenarios                  0.4                      0.0   \n",
       "4  moral_scenarios                  0.0                      0.6   \n",
       "\n",
       "   sr_mistral-7b-inst_CHAT  maj_gemma-7b-it_CHAT  maj_llama2-13b-chat_CHAT  \\\n",
       "0                      0.2                   0.0                       1.0   \n",
       "1                      0.5                   0.0                       0.0   \n",
       "2                      0.4                   0.0                       1.0   \n",
       "3                      0.6                   0.0                       0.0   \n",
       "4                      0.7                   0.0                       1.0   \n",
       "\n",
       "   maj_mistral-7b-inst_CHAT  ...  \\\n",
       "0                       0.0  ...   \n",
       "1                       1.0  ...   \n",
       "2                       1.0  ...   \n",
       "3                       1.0  ...   \n",
       "4                       1.0  ...   \n",
       "\n",
       "                               auto_answers_gemma-7b  \\\n",
       "0  ['B', 'D', 'D', 'C', 'C', 'D', 'D', 'C', 'D', ...   \n",
       "1  ['B', 'A', 'B', 'B', 'B', 'A', 'B', 'A', 'B', ...   \n",
       "2  ['B', 'C', 'D', 'D', 'D', 'B', 'D', 'B', 'A', ...   \n",
       "3  ['A', 'B', 'B', 'A', 'B', 'A', 'A', 'B', 'B', ...   \n",
       "4  ['D', 'C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...   \n",
       "\n",
       "                           auto_answers_llama2-7b-lm  \\\n",
       "0  ['A', 'B', 'B', 'D', 'D', 'D', 'D', 'D', 'D', ...   \n",
       "1  ['B', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', ...   \n",
       "2  ['D', 'D', 'D', 'INVALID', 'A', 'D', 'C', 'D',...   \n",
       "3  ['A', 'A', 'D', 'B', 'B', 'D', 'A', 'A', 'A', ...   \n",
       "4  ['D', 'D', 'D', 'INVALID', 'D', 'D', 'D', 'D',...   \n",
       "\n",
       "                            auto_answers_metamath-7b  \\\n",
       "0  ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...   \n",
       "1  ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...   \n",
       "2  ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...   \n",
       "3  ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'B', 'D', ...   \n",
       "4  ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...   \n",
       "\n",
       "                          auto_answers_mistral-7b-lm  \\\n",
       "0  ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'B', 'D', ...   \n",
       "1  ['A', 'A', 'A', 'B', 'A', 'A', 'B', 'B', 'A', ...   \n",
       "2  ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...   \n",
       "3  ['A', 'B', 'A', 'D', 'A', 'A', 'A', 'A', 'B', ...   \n",
       "4  ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...   \n",
       "\n",
       "                                auto_answers_olmo-7b  \\\n",
       "0  ['C', 'C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', ...   \n",
       "1  ['D', 'C', 'B', 'B', 'B', 'A', 'D', 'D', 'B', ...   \n",
       "2  ['B', 'D', 'D', 'D', 'A', 'B', 'C', 'INVALID',...   \n",
       "3  ['D', 'A', 'C', 'D', 'C', 'D', 'A', 'C', 'D', ...   \n",
       "4  ['D', 'D', 'D', 'A', 'D', 'B', 'C', 'D', 'B', ...   \n",
       "\n",
       "                               auto_answers_opt-6.7b  rl_gemma-7b  \\\n",
       "0  ['C', 'C', 'D', 'C', 'B', 'D', 'D', 'D', 'D', ...     0.238095   \n",
       "1  ['B', 'A', 'C', 'B', 'B', 'C', 'C', 'D', 'B', ...     0.142857   \n",
       "2  ['C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'B', ...     0.238095   \n",
       "3  ['B', 'INVALID', 'A', 'D', 'D', 'D', 'B', 'D',...     0.428571   \n",
       "4  ['D', 'D', 'C', 'D', 'C', 'D', 'D', 'B', 'D', ...     0.238095   \n",
       "\n",
       "   rl_mistral-7b-lm  rl_llama2-13b-chat  rl_gemma-7b-it  \n",
       "0          0.238095            0.238095        0.000000  \n",
       "1          1.000000            0.142857        0.142857  \n",
       "2          0.238095            0.238095        0.000000  \n",
       "3          0.428571            0.428571        0.428571  \n",
       "4          0.238095            0.238095        0.000000  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = \"gsm8k\"\n",
    "\n",
    "if data_name == \"gsm8k\":\n",
    "    path = '/root/COLM/dataset/gsm8k_unified_data_v4.csv'\n",
    "    data_all = pd.read_csv(path, encoding=\"utf-8\")\n",
    "\n",
    "print(data_all.shape, data_name)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a69bb48a-f147-473d-8a7f-72354c517224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question',\n",
       " 'gold_answer',\n",
       " 'split',\n",
       " 'sr_falcon-7b',\n",
       " 'sr_gemma-7b',\n",
       " 'sr_llama2-7b-lm',\n",
       " 'sr_metamath-7b',\n",
       " 'sr_mistral-7b-lm',\n",
       " 'sr_olmo-7b',\n",
       " 'sr_opt-6.7b',\n",
       " 'maj_falcon-7b',\n",
       " 'maj_gemma-7b_LM',\n",
       " 'maj_llama2-7b-lm_LM',\n",
       " 'maj_metamath-7b_LM',\n",
       " 'maj_mistral-7b-lm_LM',\n",
       " 'maj_olmo-7b',\n",
       " 'maj_opt-6.7b',\n",
       " 'auto_answers_falcon-7b',\n",
       " 'auto_answers_maj_gemma-7b_LM',\n",
       " 'auto_answers_maj_llama2-7b-lm_LM',\n",
       " 'auto_answers_maj_metamath-7b_LM',\n",
       " 'auto_answers_maj_mistral-7b-lm_LM',\n",
       " 'auto_answers_olmo-7b',\n",
       " 'auto_answers_opt-6.7b',\n",
       " 'sr_gemma-7b-it',\n",
       " 'sr_llama2-13b-chat',\n",
       " 'sr_mistral-7b-inst',\n",
       " 'maj_gemma-7b-it_CHAT',\n",
       " 'maj_llama2-13b-chat_CHAT',\n",
       " 'maj_mistral-7b-inst_CHAT',\n",
       " 'auto_answers_maj_gemma-7b-it_CHAT',\n",
       " 'auto_answers_maj_llama2-13b-chat_CHAT',\n",
       " 'auto_answers_maj_mistral-7b-inst_CHAT',\n",
       " 'rl_gemma-7b',\n",
       " 'rl_mistral-7b-lm',\n",
       " 'rl_llama2-13b-chat',\n",
       " 'rl_gemma-7b-it']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.rename(columns = {'maj_gemma-7b':'maj_gemma-7b_LM', 'maj_metamath-7b':'maj_metamath-7b_LM', 'maj_mistral-7b-lm':'maj_mistral-7b-lm_LM', \"maj_llama2-7b-lm\":\"maj_llama2-7b-lm_LM\",\\\n",
    "                              'maj_gemma-7b-it':'maj_gemma-7b-it_CHAT', 'maj_llama2-13b-chat':'maj_llama2-13b-chat_CHAT', 'maj_mistral-7b-inst':'maj_mistral-7b-inst_CHAT', \\\n",
    "                              \"auto_answers_gemma-7b\":\"auto_answers_maj_gemma-7b_LM\", \"auto_answers_metamath-7b\":\"auto_answers_maj_metamath-7b_LM\", \"auto_answers_mistral-7b-lm\":\"auto_answers_maj_mistral-7b-lm_LM\", \"auto_answers_llama2-7b-lm\":\"auto_answers_maj_llama2-7b-lm_LM\",\\\n",
    "                             'auto_answers_gemma-7b-it':'auto_answers_maj_gemma-7b-it_CHAT', 'auto_answers_llama2-13b-chat':'auto_answers_maj_llama2-13b-chat_CHAT', 'auto_answers_mistral-7b-inst':'auto_answers_maj_mistral-7b-inst_CHAT'}, inplace = True)\\\n",
    "\n",
    "column_names = data_all.columns.tolist()\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e7ee9ad2-1a77-4271-b9c8-88db31189a52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>split</th>\n",
       "      <th>maj_gemma-7b_LM</th>\n",
       "      <th>maj_metamath-7b_LM</th>\n",
       "      <th>maj_mistral-7b-lm_LM</th>\n",
       "      <th>maj_gemma-7b-it_CHAT</th>\n",
       "      <th>maj_llama2-13b-chat_CHAT</th>\n",
       "      <th>maj_mistral-7b-inst_CHAT</th>\n",
       "      <th>auto_answers_maj_gemma-7b_LM</th>\n",
       "      <th>auto_answers_maj_metamath-7b_LM</th>\n",
       "      <th>auto_answers_maj_mistral-7b-lm_LM</th>\n",
       "      <th>auto_answers_maj_gemma-7b-it_CHAT</th>\n",
       "      <th>auto_answers_maj_llama2-13b-chat_CHAT</th>\n",
       "      <th>auto_answers_maj_mistral-7b-inst_CHAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalia sold clips to 48 of her friends in Apr...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[96.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....</td>\n",
       "      <td>[72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....</td>\n",
       "      <td>[72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....</td>\n",
       "      <td>[72.0, 24.0, 72.0, 72.0, 72.0, 'INVALID', 72.0...</td>\n",
       "      <td>[72.0, 72.0, 72.0, 72.0, 720.0, 72.0, 24.0, 72...</td>\n",
       "      <td>[96.0, 24.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weng earns $12 an hour for babysitting. Yester...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[10.0, 10.0, 600.0, 10.0, 10.0, 10000000000.0,...</td>\n",
       "      <td>[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10....</td>\n",
       "      <td>[10.0, 99.0, 10.0, 5.0, 10.0, 60.0, 10.0, 60.0...</td>\n",
       "      <td>[6.0, 6.0, 6.0, 6.0, 6.0, 'INVALID', 'INVALID'...</td>\n",
       "      <td>[60.0, 9.96, 60.0, 60.0, 60.0, 60.0, 'INVALID'...</td>\n",
       "      <td>[9.99992, 10.0, 12.0, 10.4, 10.0, 9.996, 12.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty is saving money for a new wallet which c...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[5.0, 45.0, 55.0, 5.0, 10.0, 5.0, 35.0, 5.0, 5...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>[55.0, 55.0, 155.0, 55.0, 5.0, 55.0, 55.0, 45....</td>\n",
       "      <td>[-5.0, 30.0, 'INVALID', 45.0, 30.0, 35.0, 35.0...</td>\n",
       "      <td>[45.0, 45.0, 45.0, 5.0, 55.0, 5.0, 5.0, 55.0, ...</td>\n",
       "      <td>[5.0, 75.0, 5.0, 105.0, 55.0, 5.0, 92.5, 25.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julie is reading a 120-page book. Yesterday, s...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[84.0, 42.0, 84.0, 42.0, 42.0, 42.0, 84.0, 54....</td>\n",
       "      <td>[42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42....</td>\n",
       "      <td>[96.0, 84.0, 96.0, 96.0, 24.0, 48.0, 25.0, 72....</td>\n",
       "      <td>[72.0, 84.0, 72.0, 42.0, 48.0, 84.0, 24.0, 42....</td>\n",
       "      <td>[60.0, 64.0, 60.0, 44.0, 96.0, 84.0, 42.0, 96....</td>\n",
       "      <td>[42.0, 72.0, 42.0, 54.0, 12.0, 60.0, 24.0, 'IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James writes a 3-page letter to 2 different fr...</td>\n",
       "      <td>624.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[312.0, 144.0, 600.0, 624.0, 468.0, 104.0, 312...</td>\n",
       "      <td>[624.0, 624.0, 624.0, 624.0, 624.0, 624.0, 624...</td>\n",
       "      <td>[144.0, 208.0, 624.0, 312.0, 312.0, 312.0, 312...</td>\n",
       "      <td>[208.0, 3.0, 104.0, 104.0, 'INVALID', 156.0, 1...</td>\n",
       "      <td>[312.0, 312.0, 312.0, 312.0, 624.0, 312.0, 208...</td>\n",
       "      <td>[624.0, 312.0, 1296.0, 312.0, 312.0, 312.0, 62...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  gold_answer  split  \\\n",
       "0  Natalia sold clips to 48 of her friends in Apr...         72.0  train   \n",
       "1  Weng earns $12 an hour for babysitting. Yester...         10.0  train   \n",
       "2  Betty is saving money for a new wallet which c...          5.0  train   \n",
       "3  Julie is reading a 120-page book. Yesterday, s...         42.0  train   \n",
       "4  James writes a 3-page letter to 2 different fr...        624.0  train   \n",
       "\n",
       "   maj_gemma-7b_LM  maj_metamath-7b_LM  maj_mistral-7b-lm_LM  \\\n",
       "0              1.0                 1.0                   1.0   \n",
       "1              1.0                 1.0                   1.0   \n",
       "2              1.0                 1.0                   0.0   \n",
       "3              1.0                 1.0                   0.0   \n",
       "4              0.0                 1.0                   0.0   \n",
       "\n",
       "   maj_gemma-7b-it_CHAT  maj_llama2-13b-chat_CHAT  maj_mistral-7b-inst_CHAT  \\\n",
       "0                   1.0                       1.0                       1.0   \n",
       "1                   0.0                       0.0                       1.0   \n",
       "2                   0.0                       1.0                       1.0   \n",
       "3                   1.0                       0.0                       1.0   \n",
       "4                   0.0                       0.0                       0.0   \n",
       "\n",
       "                        auto_answers_maj_gemma-7b_LM  \\\n",
       "0  [96.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....   \n",
       "1  [10.0, 10.0, 600.0, 10.0, 10.0, 10000000000.0,...   \n",
       "2  [5.0, 45.0, 55.0, 5.0, 10.0, 5.0, 35.0, 5.0, 5...   \n",
       "3  [84.0, 42.0, 84.0, 42.0, 42.0, 42.0, 84.0, 54....   \n",
       "4  [312.0, 144.0, 600.0, 624.0, 468.0, 104.0, 312...   \n",
       "\n",
       "                     auto_answers_maj_metamath-7b_LM  \\\n",
       "0  [72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....   \n",
       "1  [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10....   \n",
       "2  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "3  [42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42....   \n",
       "4  [624.0, 624.0, 624.0, 624.0, 624.0, 624.0, 624...   \n",
       "\n",
       "                   auto_answers_maj_mistral-7b-lm_LM  \\\n",
       "0  [72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....   \n",
       "1  [10.0, 99.0, 10.0, 5.0, 10.0, 60.0, 10.0, 60.0...   \n",
       "2  [55.0, 55.0, 155.0, 55.0, 5.0, 55.0, 55.0, 45....   \n",
       "3  [96.0, 84.0, 96.0, 96.0, 24.0, 48.0, 25.0, 72....   \n",
       "4  [144.0, 208.0, 624.0, 312.0, 312.0, 312.0, 312...   \n",
       "\n",
       "                   auto_answers_maj_gemma-7b-it_CHAT  \\\n",
       "0  [72.0, 24.0, 72.0, 72.0, 72.0, 'INVALID', 72.0...   \n",
       "1  [6.0, 6.0, 6.0, 6.0, 6.0, 'INVALID', 'INVALID'...   \n",
       "2  [-5.0, 30.0, 'INVALID', 45.0, 30.0, 35.0, 35.0...   \n",
       "3  [72.0, 84.0, 72.0, 42.0, 48.0, 84.0, 24.0, 42....   \n",
       "4  [208.0, 3.0, 104.0, 104.0, 'INVALID', 156.0, 1...   \n",
       "\n",
       "               auto_answers_maj_llama2-13b-chat_CHAT  \\\n",
       "0  [72.0, 72.0, 72.0, 72.0, 720.0, 72.0, 24.0, 72...   \n",
       "1  [60.0, 9.96, 60.0, 60.0, 60.0, 60.0, 'INVALID'...   \n",
       "2  [45.0, 45.0, 45.0, 5.0, 55.0, 5.0, 5.0, 55.0, ...   \n",
       "3  [60.0, 64.0, 60.0, 44.0, 96.0, 84.0, 42.0, 96....   \n",
       "4  [312.0, 312.0, 312.0, 312.0, 624.0, 312.0, 208...   \n",
       "\n",
       "               auto_answers_maj_mistral-7b-inst_CHAT  \n",
       "0  [96.0, 24.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....  \n",
       "1  [9.99992, 10.0, 12.0, 10.4, 10.0, 9.996, 12.0,...  \n",
       "2  [5.0, 75.0, 5.0, 105.0, 55.0, 5.0, 92.5, 25.0,...  \n",
       "3  [42.0, 72.0, 42.0, 54.0, 12.0, 60.0, 24.0, 'IN...  \n",
       "4  [624.0, 312.0, 1296.0, 312.0, 312.0, 312.0, 62...  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retain required colmns\n",
    "if data_name == 'gsm8k':\n",
    "    data_all = data_all[['question', 'gold_answer', 'split', 'maj_gemma-7b_LM', 'maj_metamath-7b_LM', 'maj_mistral-7b-lm_LM', 'maj_gemma-7b-it_CHAT', \n",
    "                     'maj_llama2-13b-chat_CHAT', 'maj_mistral-7b-inst_CHAT', \"auto_answers_maj_gemma-7b_LM\", \"auto_answers_maj_metamath-7b_LM\", \\\n",
    "                     \"auto_answers_maj_mistral-7b-lm_LM\", 'auto_answers_maj_gemma-7b-it_CHAT','auto_answers_maj_llama2-13b-chat_CHAT', \\\n",
    "                     'auto_answers_maj_mistral-7b-inst_CHAT']]\n",
    "elif data_name == 'mmlu':\n",
    "    data_all = data_all[['question', 'gold_answer', 'split', \"subject\", 'maj_gemma-7b_LM', 'maj_metamath-7b_LM', 'maj_mistral-7b-lm_LM', 'maj_gemma-7b-it_CHAT', 'maj_llama2-7b-lm_LM',\n",
    "                     'maj_llama2-13b-chat_CHAT', 'maj_mistral-7b-inst_CHAT', \"auto_answers_maj_gemma-7b_LM\", \"auto_answers_maj_metamath-7b_LM\", \"auto_answers_maj_llama2-7b-lm_LM\", \\\n",
    "                     \"auto_answers_maj_mistral-7b-lm_LM\", 'auto_answers_maj_gemma-7b-it_CHAT','auto_answers_maj_llama2-13b-chat_CHAT', \\\n",
    "                     'auto_answers_maj_mistral-7b-inst_CHAT']]\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "97e10fd2-d682-48d0-b3bc-82053f89eb10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>split</th>\n",
       "      <th>auto_answers_maj_gemma-7b_LM</th>\n",
       "      <th>auto_answers_maj_metamath-7b_LM</th>\n",
       "      <th>auto_answers_maj_mistral-7b-lm_LM</th>\n",
       "      <th>auto_answers_maj_gemma-7b-it_CHAT</th>\n",
       "      <th>auto_answers_maj_llama2-13b-chat_CHAT</th>\n",
       "      <th>auto_answers_maj_mistral-7b-inst_CHAT</th>\n",
       "      <th>maj_gemma-7b-it_CHAT</th>\n",
       "      <th>maj_llama2-13b-chat_CHAT</th>\n",
       "      <th>maj_mistral-7b-inst_CHAT</th>\n",
       "      <th>maj_mistral-7b-lm_LM</th>\n",
       "      <th>maj_gemma-7b_LM</th>\n",
       "      <th>maj_metamath-7b_LM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalia sold clips to 48 of her friends in Apr...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>train</td>\n",
       "      <td>[96.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....</td>\n",
       "      <td>[72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....</td>\n",
       "      <td>[72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....</td>\n",
       "      <td>[72.0, 24.0, 72.0, 72.0, 72.0, 'INVALID', 72.0...</td>\n",
       "      <td>[72.0, 72.0, 72.0, 72.0, 720.0, 72.0, 24.0, 72...</td>\n",
       "      <td>[96.0, 24.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weng earns $12 an hour for babysitting. Yester...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>train</td>\n",
       "      <td>[10.0, 10.0, 600.0, 10.0, 10.0, 10000000000.0,...</td>\n",
       "      <td>[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10....</td>\n",
       "      <td>[10.0, 99.0, 10.0, 5.0, 10.0, 60.0, 10.0, 60.0...</td>\n",
       "      <td>[6.0, 6.0, 6.0, 6.0, 6.0, 'INVALID', 'INVALID'...</td>\n",
       "      <td>[60.0, 9.96, 60.0, 60.0, 60.0, 60.0, 'INVALID'...</td>\n",
       "      <td>[9.99992, 10.0, 12.0, 10.4, 10.0, 9.996, 12.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty is saving money for a new wallet which c...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>train</td>\n",
       "      <td>[5.0, 45.0, 55.0, 5.0, 10.0, 5.0, 35.0, 5.0, 5...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>[55.0, 55.0, 155.0, 55.0, 5.0, 55.0, 55.0, 45....</td>\n",
       "      <td>[-5.0, 30.0, 'INVALID', 45.0, 30.0, 35.0, 35.0...</td>\n",
       "      <td>[45.0, 45.0, 45.0, 5.0, 55.0, 5.0, 5.0, 55.0, ...</td>\n",
       "      <td>[5.0, 75.0, 5.0, 105.0, 55.0, 5.0, 92.5, 25.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julie is reading a 120-page book. Yesterday, s...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>train</td>\n",
       "      <td>[84.0, 42.0, 84.0, 42.0, 42.0, 42.0, 84.0, 54....</td>\n",
       "      <td>[42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42....</td>\n",
       "      <td>[96.0, 84.0, 96.0, 96.0, 24.0, 48.0, 25.0, 72....</td>\n",
       "      <td>[72.0, 84.0, 72.0, 42.0, 48.0, 84.0, 24.0, 42....</td>\n",
       "      <td>[60.0, 64.0, 60.0, 44.0, 96.0, 84.0, 42.0, 96....</td>\n",
       "      <td>[42.0, 72.0, 42.0, 54.0, 12.0, 60.0, 24.0, 'IN...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James writes a 3-page letter to 2 different fr...</td>\n",
       "      <td>624.0</td>\n",
       "      <td>train</td>\n",
       "      <td>[312.0, 144.0, 600.0, 624.0, 468.0, 104.0, 312...</td>\n",
       "      <td>[624.0, 624.0, 624.0, 624.0, 624.0, 624.0, 624...</td>\n",
       "      <td>[144.0, 208.0, 624.0, 312.0, 312.0, 312.0, 312...</td>\n",
       "      <td>[208.0, 3.0, 104.0, 104.0, 'INVALID', 156.0, 1...</td>\n",
       "      <td>[312.0, 312.0, 312.0, 312.0, 624.0, 312.0, 208...</td>\n",
       "      <td>[624.0, 312.0, 1296.0, 312.0, 312.0, 312.0, 62...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  gold_answer  split  \\\n",
       "0  Natalia sold clips to 48 of her friends in Apr...         72.0  train   \n",
       "1  Weng earns $12 an hour for babysitting. Yester...         10.0  train   \n",
       "2  Betty is saving money for a new wallet which c...          5.0  train   \n",
       "3  Julie is reading a 120-page book. Yesterday, s...         42.0  train   \n",
       "4  James writes a 3-page letter to 2 different fr...        624.0  train   \n",
       "\n",
       "                        auto_answers_maj_gemma-7b_LM  \\\n",
       "0  [96.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....   \n",
       "1  [10.0, 10.0, 600.0, 10.0, 10.0, 10000000000.0,...   \n",
       "2  [5.0, 45.0, 55.0, 5.0, 10.0, 5.0, 35.0, 5.0, 5...   \n",
       "3  [84.0, 42.0, 84.0, 42.0, 42.0, 42.0, 84.0, 54....   \n",
       "4  [312.0, 144.0, 600.0, 624.0, 468.0, 104.0, 312...   \n",
       "\n",
       "                     auto_answers_maj_metamath-7b_LM  \\\n",
       "0  [72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....   \n",
       "1  [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10....   \n",
       "2  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "3  [42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42....   \n",
       "4  [624.0, 624.0, 624.0, 624.0, 624.0, 624.0, 624...   \n",
       "\n",
       "                   auto_answers_maj_mistral-7b-lm_LM  \\\n",
       "0  [72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....   \n",
       "1  [10.0, 99.0, 10.0, 5.0, 10.0, 60.0, 10.0, 60.0...   \n",
       "2  [55.0, 55.0, 155.0, 55.0, 5.0, 55.0, 55.0, 45....   \n",
       "3  [96.0, 84.0, 96.0, 96.0, 24.0, 48.0, 25.0, 72....   \n",
       "4  [144.0, 208.0, 624.0, 312.0, 312.0, 312.0, 312...   \n",
       "\n",
       "                   auto_answers_maj_gemma-7b-it_CHAT  \\\n",
       "0  [72.0, 24.0, 72.0, 72.0, 72.0, 'INVALID', 72.0...   \n",
       "1  [6.0, 6.0, 6.0, 6.0, 6.0, 'INVALID', 'INVALID'...   \n",
       "2  [-5.0, 30.0, 'INVALID', 45.0, 30.0, 35.0, 35.0...   \n",
       "3  [72.0, 84.0, 72.0, 42.0, 48.0, 84.0, 24.0, 42....   \n",
       "4  [208.0, 3.0, 104.0, 104.0, 'INVALID', 156.0, 1...   \n",
       "\n",
       "               auto_answers_maj_llama2-13b-chat_CHAT  \\\n",
       "0  [72.0, 72.0, 72.0, 72.0, 720.0, 72.0, 24.0, 72...   \n",
       "1  [60.0, 9.96, 60.0, 60.0, 60.0, 60.0, 'INVALID'...   \n",
       "2  [45.0, 45.0, 45.0, 5.0, 55.0, 5.0, 5.0, 55.0, ...   \n",
       "3  [60.0, 64.0, 60.0, 44.0, 96.0, 84.0, 42.0, 96....   \n",
       "4  [312.0, 312.0, 312.0, 312.0, 624.0, 312.0, 208...   \n",
       "\n",
       "               auto_answers_maj_mistral-7b-inst_CHAT  maj_gemma-7b-it_CHAT  \\\n",
       "0  [96.0, 24.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....                     1   \n",
       "1  [9.99992, 10.0, 12.0, 10.4, 10.0, 9.996, 12.0,...                     0   \n",
       "2  [5.0, 75.0, 5.0, 105.0, 55.0, 5.0, 92.5, 25.0,...                     0   \n",
       "3  [42.0, 72.0, 42.0, 54.0, 12.0, 60.0, 24.0, 'IN...                     1   \n",
       "4  [624.0, 312.0, 1296.0, 312.0, 312.0, 312.0, 62...                     0   \n",
       "\n",
       "   maj_llama2-13b-chat_CHAT  maj_mistral-7b-inst_CHAT  maj_mistral-7b-lm_LM  \\\n",
       "0                         1                         1                     1   \n",
       "1                         0                         1                     1   \n",
       "2                         1                         1                     0   \n",
       "3                         0                         1                     0   \n",
       "4                         0                         0                     0   \n",
       "\n",
       "   maj_gemma-7b_LM  maj_metamath-7b_LM  \n",
       "0                1                   1  \n",
       "1                1                   1  \n",
       "2                1                   1  \n",
       "3                1                   1  \n",
       "4                0                   1  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mostfreqentval(mylist, gold_val):\n",
    "    if data_name == \"gsm8k\":\n",
    "        my_list = [ float(item) for item in mylist if item != \"INVALID\"]\n",
    "        counter = Counter(my_list)\n",
    "        most_common_values = counter.most_common()\n",
    "        if len(most_common_values) == 0:\n",
    "            topfrq = 0.9999989898999998989899\n",
    "        else:\n",
    "            topfrq = most_common_values[0][0]\n",
    "        if float(topfrq) == float(gold_val):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif data_name == \"mmlu\":\n",
    "        my_list = [ item.strip() for item in mylist]\n",
    "        counter = Counter(my_list)\n",
    "        most_common_values = counter.most_common()\n",
    "        if len(most_common_values) == 0:\n",
    "            topfrq = 0.9999989898999998989899\n",
    "        else:\n",
    "            topfrq = most_common_values[0][0]\n",
    "        if topfrq.strip() == gold_val.strip():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "if data_name == \"gsm8k\":\n",
    "    kepping_llms = [\"maj_gemma-7b-it_CHAT\", \"maj_llama2-13b-chat_CHAT\", \"maj_mistral-7b-inst_CHAT\", \"maj_mistral-7b-lm_LM\", \"maj_gemma-7b_LM\", \"maj_metamath-7b_LM\"]\n",
    "elif data_name == \"mmlu\":\n",
    "    kepping_llms = [\"maj_gemma-7b-it_CHAT\", \"maj_llama2-13b-chat_CHAT\", \"maj_mistral-7b-inst_CHAT\", \"maj_mistral-7b-lm_LM\", \"maj_gemma-7b_LM\", \"maj_metamath-7b_LM\", \"maj_llama2-7b-lm_LM\"]\n",
    " \n",
    "for llm_name in kepping_llms:\n",
    "    del data_all[llm_name]\n",
    "    data_all[llm_name] = [ mostfreqentval(eval(item), gval) for item, gval in zip(data_all[\"auto_answers_\"+str(llm_name)].values.tolist(), data_all[\"gold_answer\"].values.tolist())]\n",
    "\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "e356eaf5-01fb-4025-ac7c-65f223ab4c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['maj_gemma-7b-it_CHAT', 'maj_llama2-13b-chat_CHAT', 'maj_mistral-7b-inst_CHAT', 'maj_mistral-7b-lm_LM', 'maj_gemma-7b_LM', 'maj_metamath-7b_LM']\n",
      "['maj_metamath-7b_LM', 'maj_gemma-7b_LM', 'maj_mistral-7b-lm_LM', 'maj_mistral-7b-inst_CHAT', 'maj_llama2-13b-chat_CHAT', 'maj_gemma-7b-it_CHAT']\n",
      "['maj_metamath-7b_LM', 'maj_gemma-7b_LM']\n",
      "['maj_metamath-7b_LM', 'maj_gemma-7b_LM', 'maj_mistral-7b-lm_LM']\n",
      "['maj_metamath-7b_LM', 'maj_gemma-7b_LM', 'maj_mistral-7b-lm_LM', 'maj_mistral-7b-inst_CHAT']\n",
      "['maj_metamath-7b_LM', 'maj_gemma-7b_LM', 'maj_mistral-7b-lm_LM', 'maj_mistral-7b-inst_CHAT', 'maj_llama2-13b-chat_CHAT']\n",
      "['maj_metamath-7b_LM', 'maj_gemma-7b_LM', 'maj_mistral-7b-lm_LM', 'maj_mistral-7b-inst_CHAT', 'maj_llama2-13b-chat_CHAT', 'maj_gemma-7b-it_CHAT']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>split</th>\n",
       "      <th>maj_gemma-7b_LM</th>\n",
       "      <th>maj_metamath-7b_LM</th>\n",
       "      <th>maj_mistral-7b-lm_LM</th>\n",
       "      <th>maj_gemma-7b-it_CHAT</th>\n",
       "      <th>maj_llama2-13b-chat_CHAT</th>\n",
       "      <th>maj_mistral-7b-inst_CHAT</th>\n",
       "      <th>auto_answers_maj_gemma-7b_LM</th>\n",
       "      <th>...</th>\n",
       "      <th>maj_2</th>\n",
       "      <th>maj_2_model</th>\n",
       "      <th>maj_3</th>\n",
       "      <th>maj_3_model</th>\n",
       "      <th>maj_4</th>\n",
       "      <th>maj_4_model</th>\n",
       "      <th>maj_5</th>\n",
       "      <th>maj_5_model</th>\n",
       "      <th>maj_6</th>\n",
       "      <th>maj_6_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalia sold clips to 48 of her friends in Apr...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[96.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHAT]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weng earns $12 an hour for babysitting. Yester...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[10.0, 10.0, 600.0, 10.0, 10.0, 10000000000.0,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[maj_mistral-7b-inst_CHAT]</td>\n",
       "      <td>[0, 0, 1, 1]</td>\n",
       "      <td>[maj_mistral-7b-inst_CHAT, maj_mistral-7b-lm_LM]</td>\n",
       "      <td>[0, 0, 1, 1, 1]</td>\n",
       "      <td>[maj_mistral-7b-inst_CHAT, maj_mistral-7b-lm_L...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1]</td>\n",
       "      <td>[maj_mistral-7b-inst_CHAT, maj_mistral-7b-lm_L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty is saving money for a new wallet which c...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.0, 45.0, 55.0, 5.0, 10.0, 5.0, 35.0, 5.0, 5...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[maj_llama2-13b-chat_CHAT]</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>[maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "      <td>[maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...</td>\n",
       "      <td>[0, 1, 1, 0, 1]</td>\n",
       "      <td>[maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...</td>\n",
       "      <td>[0, 1, 1, 0, 1, 1]</td>\n",
       "      <td>[maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julie is reading a 120-page book. Yesterday, s...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[84.0, 42.0, 84.0, 42.0, 42.0, 42.0, 84.0, 54....</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT]</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHAT]</td>\n",
       "      <td>[1, 0, 1, 0]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHAT]</td>\n",
       "      <td>[1, 0, 1, 0, 1]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHA...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1]</td>\n",
       "      <td>[maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James writes a 3-page letter to 2 different fr...</td>\n",
       "      <td>624.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[312.0, 144.0, 600.0, 624.0, 468.0, 104.0, 312...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[maj_metamath-7b_LM]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  gold_answer  split  \\\n",
       "0  Natalia sold clips to 48 of her friends in Apr...         72.0  train   \n",
       "1  Weng earns $12 an hour for babysitting. Yester...         10.0  train   \n",
       "2  Betty is saving money for a new wallet which c...          5.0  train   \n",
       "3  Julie is reading a 120-page book. Yesterday, s...         42.0  train   \n",
       "4  James writes a 3-page letter to 2 different fr...        624.0  train   \n",
       "\n",
       "   maj_gemma-7b_LM  maj_metamath-7b_LM  maj_mistral-7b-lm_LM  \\\n",
       "0                1                   1                     1   \n",
       "1                1                   1                     1   \n",
       "2                1                   1                     0   \n",
       "3                1                   1                     0   \n",
       "4                0                   1                     0   \n",
       "\n",
       "   maj_gemma-7b-it_CHAT  maj_llama2-13b-chat_CHAT  maj_mistral-7b-inst_CHAT  \\\n",
       "0                     1                         1                         1   \n",
       "1                     0                         0                         1   \n",
       "2                     0                         1                         1   \n",
       "3                     1                         0                         1   \n",
       "4                     0                         0                         0   \n",
       "\n",
       "                        auto_answers_maj_gemma-7b_LM  ...   maj_2  \\\n",
       "0  [96.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72....  ...  [1, 1]   \n",
       "1  [10.0, 10.0, 600.0, 10.0, 10.0, 10000000000.0,...  ...  [0, 0]   \n",
       "2  [5.0, 45.0, 55.0, 5.0, 10.0, 5.0, 35.0, 5.0, 5...  ...  [0, 1]   \n",
       "3  [84.0, 42.0, 84.0, 42.0, 42.0, 42.0, 84.0, 54....  ...  [1, 0]   \n",
       "4  [312.0, 144.0, 600.0, 624.0, 468.0, 104.0, 312...  ...  [0, 0]   \n",
       "\n",
       "                                        maj_2_model      maj_3  \\\n",
       "0  [maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHAT]  [1, 1, 1]   \n",
       "1                                                []  [0, 0, 1]   \n",
       "2                        [maj_llama2-13b-chat_CHAT]  [0, 1, 1]   \n",
       "3                            [maj_gemma-7b-it_CHAT]  [1, 0, 1]   \n",
       "4                                                []  [0, 0, 0]   \n",
       "\n",
       "                                         maj_3_model         maj_4  \\\n",
       "0  [maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...  [1, 1, 1, 1]   \n",
       "1                         [maj_mistral-7b-inst_CHAT]  [0, 0, 1, 1]   \n",
       "2  [maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...  [0, 1, 1, 0]   \n",
       "3   [maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHAT]  [1, 0, 1, 0]   \n",
       "4                                                 []  [0, 0, 0, 0]   \n",
       "\n",
       "                                         maj_4_model            maj_5  \\\n",
       "0  [maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...  [1, 1, 1, 1, 1]   \n",
       "1   [maj_mistral-7b-inst_CHAT, maj_mistral-7b-lm_LM]  [0, 0, 1, 1, 1]   \n",
       "2  [maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...  [0, 1, 1, 0, 1]   \n",
       "3   [maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHAT]  [1, 0, 1, 0, 1]   \n",
       "4                                                 []  [0, 0, 0, 0, 0]   \n",
       "\n",
       "                                         maj_5_model               maj_6  \\\n",
       "0  [maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...  [1, 1, 1, 1, 1, 1]   \n",
       "1  [maj_mistral-7b-inst_CHAT, maj_mistral-7b-lm_L...  [0, 0, 1, 1, 1, 1]   \n",
       "2  [maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...  [0, 1, 1, 0, 1, 1]   \n",
       "3  [maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHA...  [1, 0, 1, 0, 1, 1]   \n",
       "4                                                 []  [0, 0, 0, 0, 0, 1]   \n",
       "\n",
       "                                         maj_6_model  \n",
       "0  [maj_gemma-7b-it_CHAT, maj_llama2-13b-chat_CHA...  \n",
       "1  [maj_mistral-7b-inst_CHAT, maj_mistral-7b-lm_L...  \n",
       "2  [maj_llama2-13b-chat_CHAT, maj_mistral-7b-inst...  \n",
       "3  [maj_gemma-7b-it_CHAT, maj_mistral-7b-inst_CHA...  \n",
       "4                               [maj_metamath-7b_LM]  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if data_name == 'gsm8k':\n",
    "    keep_llms_old = [\"maj_gemma-7b-it_CHAT\", \"maj_llama2-13b-chat_CHAT\", \"maj_mistral-7b-inst_CHAT\", \"maj_mistral-7b-lm_LM\", \"maj_gemma-7b_LM\", \"maj_metamath-7b_LM\"]\n",
    "elif data_name == 'mmlu':\n",
    "    keep_llms_old = [\"maj_metamath-7b_LM\", \"maj_gemma-7b-it_CHAT\", \"maj_mistral-7b-inst_CHAT\", \"maj_llama2-7b-lm_LM\", \"maj_llama2-13b-chat_CHAT\", \"maj_mistral-7b-lm_LM\", \"maj_gemma-7b_LM\"]\n",
    "\n",
    "print(keep_llms_old)\n",
    "keep_llms = keep_llms_old[::-1]\n",
    "print(keep_llms)\n",
    "    \n",
    "for col_name in keep_llms:\n",
    "    data_all[col_name] = [ int(item) for item in data_all[col_name].values.tolist()]\n",
    "\n",
    "for i in range(len(keep_llms)-1):\n",
    "    subset_llms =  keep_llms[0:i+2]\n",
    "    id2mod = { i:val for i, val in enumerate(subset_llms)} \n",
    "    mod2id = { val:1 for i, val in enumerate(subset_llms)}\n",
    "    print(subset_llms)\n",
    "    data_all[f'maj_{i+2}'] = [ [ int(val) for val in item ] for item in data_all[subset_llms].values.tolist()]\n",
    "    data_all[f'maj_{i+2}_model'] = [ [ id2mod[i] for i, val in enumerate(item) if id2mod[i] in subset_llms and val != 0] for item in data_all[f'maj_{i+2}'].tolist()]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7131bc96-f84e-4b51-a6ce-08520b4d30e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6816, 25) (359, 25) (1319, 25)\n"
     ]
    }
   ],
   "source": [
    "if data_name == 'gsm8k':\n",
    "    train = data_all.loc[data_all['split'] == 'train']\n",
    "    test_data = data_all.loc[data_all['split'] == 'test']\n",
    "    train_data, val_data = train_test_split(train, test_size=0.05, random_state=1)\n",
    "    print(train_data.shape, val_data.shape, test_data.shape)\n",
    "elif data_name == 'mmlu':\n",
    "    train_data = data_all.loc[data_all['split'] == 'train']\n",
    "    test_data = data_all.loc[data_all['split'] == 'test']\n",
    "    val_data = data_all.loc[data_all['split'] == 'val']\n",
    "    print(train_data.shape, val_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1457bd25-fb47-4f42-876e-9b6a1ceb5433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Train Data *************\n",
      "maj_metamath-7b_LM: 6295 times (92.36%)\n",
      "maj_gemma-7b_LM: 5023 times (73.69%)\n",
      "maj_mistral-7b-lm_LM: 4049 times (59.40%)\n",
      "maj_mistral-7b-inst_CHAT: 3830 times (56.19%)\n",
      "maj_llama2-13b-chat_CHAT: 3434 times (50.38%)\n",
      "maj_gemma-7b-it_CHAT: 2841 times (41.68%)\n",
      "\n",
      "*********** Validation Data ****************\n",
      "maj_metamath-7b_LM: 331 times (92.20%)\n",
      "maj_gemma-7b_LM: 250 times (69.64%)\n",
      "maj_llama2-13b-chat_CHAT: 180 times (50.14%)\n",
      "maj_mistral-7b-lm_LM: 208 times (57.94%)\n",
      "maj_mistral-7b-inst_CHAT: 182 times (50.70%)\n",
      "maj_gemma-7b-it_CHAT: 145 times (40.39%)\n",
      "\n",
      "*********** Test Data ****************\n",
      "maj_metamath-7b_LM: 887 times (67.25%)\n",
      "maj_gemma-7b_LM: 940 times (71.27%)\n",
      "maj_mistral-7b-lm_LM: 798 times (60.50%)\n",
      "maj_mistral-7b-inst_CHAT: 748 times (56.71%)\n",
      "maj_llama2-13b-chat_CHAT: 649 times (49.20%)\n",
      "maj_gemma-7b-it_CHAT: 557 times (42.23%)\n",
      "*********** All Data ****************\n",
      "maj_metamath-7b_LM: 7787 times (88.57%)\n",
      "maj_gemma-7b_LM: 6430 times (73.13%)\n",
      "maj_mistral-7b-lm_LM: 5223 times (59.41%)\n",
      "maj_mistral-7b-inst_CHAT: 4920 times (55.96%)\n",
      "maj_llama2-13b-chat_CHAT: 4413 times (50.19%)\n",
      "maj_gemma-7b-it_CHAT: 3669 times (41.73%)\n"
     ]
    }
   ],
   "source": [
    "#label Distribution \n",
    "from collections import Counter\n",
    "\n",
    "def lab_dist(all_in):\n",
    "    temp = [ [ keep_llms[i] for i, val in enumerate(item) if val !=0 ] for item in all_in]\n",
    "    flattened_list = [item for sublist in temp for item in sublist]\n",
    "\n",
    "    # Count the occurrences of each element\n",
    "    element_counts = Counter(flattened_list)\n",
    "\n",
    "    # Display the counts\n",
    "    for element, count in element_counts.items():\n",
    "        percentage = (count / len(all_in)) * 100\n",
    "        print(f\"{element}: {count} times ({percentage:.2f}%)\")\n",
    "        \n",
    "if data_name == 'gsm8k':\n",
    "    print(\"*********** Train Data *************\")\n",
    "    lab_dist(train_data['maj_6'].tolist())\n",
    "    print(\"\")\n",
    "    print(\"*********** Validation Data ****************\")\n",
    "    lab_dist(val_data['maj_6'].tolist())\n",
    "    print(\"\")\n",
    "    print(\"*********** Test Data ****************\")\n",
    "    lab_dist(test_data['maj_6'].tolist())\n",
    "    print(\"*********** All Data ****************\")\n",
    "    lab_dist(data_all['maj_6'].tolist())\n",
    "elif data_name == 'mmlu':\n",
    "    print(\"*********** Train Data *************\")\n",
    "    lab_dist(train_data['maj_7'].tolist())\n",
    "    print(\"\")\n",
    "    print(\"*********** Validation Data ****************\")\n",
    "    lab_dist(val_data['maj_7'].tolist())\n",
    "    print(\"\")\n",
    "    print(\"*********** Test Data ****************\")\n",
    "    lab_dist(test_data['maj_7'].tolist())\n",
    "    print(\"*********** All Data ****************\")\n",
    "    lab_dist(data_all['maj_7'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "97bdf8db-b39d-4da3-a5e2-01923e627160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if data_name == 'gsm8k':\n",
    "    print(\"Saving to GSM8K\")\n",
    "    train_data.to_csv('/root/COLM/dataset/gsm8k/train_all_top.csv', index=False, encoding=\"utf-8\")\n",
    "    val_data.to_csv('/root/COLM/dataset/gsm8k/val_all_top.csv', index=False, encoding=\"utf-8\")\n",
    "    data_all.to_csv('/root/COLM/dataset/gsm8k/test_all_top.csv', index=False, encoding=\"utf-8\")\n",
    "    data_all.to_csv('/root/COLM/dataset/gsm8k/gsm8k_unified_v5.csv', index=False, encoding=\"utf-8\")\n",
    "elif data_name == 'mmlu':\n",
    "    print(\"Saving to MMLU\")\n",
    "    train_data.to_csv('/root/COLM/dataset/mmlu/train_all_top.csv', index=False, encoding=\"utf-8\")\n",
    "    val_data.to_csv('/root/COLM/dataset/mmlu/val_all_top.csv', index=False, encoding=\"utf-8\")\n",
    "    data_all.to_csv('/root/COLM/dataset/mmlu/test_all_top.csv', index=False, encoding=\"utf-8\")\n",
    "    data_all.to_csv('/root/COLM/dataset/mmlu/mmlu_unified_v5.csv', index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g5.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
